name: Crawling

on:
  schedule:
    - cron: '0 0,9 * * *'
  workflow_dispatch:

jobs:
  run_scrapy:
    name: Run scrapy
    runs-on: ubuntu-latest
    steps:
    - name: Checkout ${{ github.repository }}
      uses: actions/checkout@v2
    
    - name: Setup Python 3.8
      uses: actions/setup-python@v2
      with:
        python-version: 3.8
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install csvkit
    
    - name: Clean previous artifacts
      run: |
        rm -rf result
        mkdir -p result
    
    - name: Run scrapy
      run: |
        scrapy crawl mma -t csv -o result/raw.csv
    
    - name: Make artifacts
      run: |
        csvsort -c 1 result/raw.csv > result/all.csv
        awk '/업종|정보처리/' result/all.csv > result/it.csv
        csvsort -c 4,8 -r result/it.csv > result/it-primary.csv
        csvsort -c 8,4 -r result/it.csv > result/it-secondary.csv
    
    - name: Setup Git configurations
      run: |
        git config user.name "github-actions"
        git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
    
    - name: Add, commit and push to ${{ github.repository }}
      run: |
        git add -A
        git commit --allow-empty -m "$(TZ=Asia/Seoul date --iso-8601=minutes)"
        git pull --rebase
        git push origin HEAD
